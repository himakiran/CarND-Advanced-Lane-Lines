{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Lane Finding Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "---\n",
    "## First, I'll compute the camera calibration using chessboard images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib qt\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((6*9,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('camera_cal/calibration*.jpg')\n",
    "\n",
    "img = cv2.imread(images[0])\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#print(len(images))\n",
    "\n",
    "#Step through the list and search for chessboard corners\n",
    "for fname in images:\n",
    "    #print(fname)\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9,6),None)\n",
    "\n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "        # Draw and display the corners\n",
    "        img = cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "        # Writing the output images to the output_images folder\n",
    "        #cv2.imwrite(\"output_images/\"+fname+\"_CCoutput\"+\".jpg\",img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibrate the camera and get the Camera Matrix and Distortion co-efficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_undistort(img, mtx, dist):    \n",
    "    # Use cv2.undistort()    \n",
    "    dst = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    return dst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking distortion correction on test_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = glob.glob('test_images/test*.jpg')\n",
    "for each in images:\n",
    "    img = cv2.imread(each)\n",
    "    dst = cal_undistort(img,mtx,dist)\n",
    "    # Saving the undistorted images to the output dir\n",
    "    cv2.imwrite(\"output_images/\"+each+\"_Undistorted\"+\".jpg\",dst)\n",
    "images = glob.glob('test_images/straight_lines*.jpg')\n",
    "for each in images:\n",
    "    img = cv2.imread(each)\n",
    "    dst = cal_undistort(img,mtx,dist)\n",
    "    #Saving the undistorted images to the output dir\n",
    "    cv2.imwrite(\"output_images/\"+each+\"_Undistorted\"+\".jpg\",dst)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carrying out Perspective Transform on One Undistorted test image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = mpimg.imread('output_images/test_images/test5.jpg_Undistorted.jpg')\n",
    "plt.imshow(img)\n",
    "\n",
    "img_size = (img.shape[1], img.shape[0])\n",
    "#src = np.float32([[604,447],[677,447] ,[200,720],[1090,720]])\n",
    "# TO-DO May be you need to decrease the height of the trapezoid\n",
    "#src = np.float32([[541,492],[750,492] ,[200,720],[1096,720]])\n",
    "src = np.float32([[467,532],[822,532] ,[171,720],[1125,720]])\n",
    "dst = np.float32([[200,400],[1100,400] ,[200,720],[1100,720]])\n",
    "\n",
    "def do_perspective_transform(img):\n",
    "    M = cv2.getPerspectiveTransform(src,dst)\n",
    "    warped = cv2.warpPerspective(img,M,img_size,flags=cv2.INTER_LINEAR)\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(img)\n",
    "    ax1.set_title('Original Image', fontsize=50)\n",
    "    ax2.imshow(warped)\n",
    "    ax2.set_title('Undistorted and Warped Image', fontsize=50)\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "    return warped\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carrying out Perspective Transform on all Undistorted test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = glob.glob('output_images/test_images/test*.jpg')\n",
    "for each in images:\n",
    "    img = mpimg.imread(each)\n",
    "    do_perspective_transform(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to calculate the gradient along a given direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abs_sobel_thresh(img, orient='x', thresh_min=0, thresh_max=255):\n",
    "    \n",
    "    # Apply the following steps to img\n",
    "    # 1) Convert to grayscale\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
    "    # 2) Take the derivative in x or y given orient = 'x' or 'y'\n",
    "    if(orient=='x'):\n",
    "        sobel = cv2.Sobel(gray, cv2.CV_64F, 1, 0)\n",
    "    else:\n",
    "        sobel = cv2.Sobel(gray, cv2.CV_64F, 0, 1)\n",
    "    # 3) Take the absolute value of the derivative or gradient\n",
    "    abs_sobel = np.absolute(sobel)\n",
    "    # 4) Scale to 8-bit (0 - 255) then convert to type = np.uint8\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "\n",
    "    # 5) Create a mask of 1's where the scaled gradient magnitude \n",
    "            # is > thresh_min and < thresh_max\n",
    "    mask = (scaled_sobel >= thresh_min) & (scaled_sobel <= thresh_max)\n",
    "    sxbinary = np.zeros_like(scaled_sobel)\n",
    "    sxbinary[mask]=1\n",
    "    # 6) Return this mask as your binary_output image\n",
    "    \n",
    "    return sxbinary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to calculate the magnitude of the gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mag_thresh(img, sobel_kernel=3, mag_thresh=(0, 255)):\n",
    "    thresh_min = mag_thresh[0]\n",
    "    thresh_max = mag_thresh[1]\n",
    "    \n",
    "    # Apply the following steps to img\n",
    "    # 1) Convert to grayscale\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
    "    # 2) Take the gradient in x and y separately\n",
    "    sobel_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0)\n",
    "    sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1)\n",
    "    # 3) Calculate the magnitude \n",
    "    abs_sobelxy = np.sqrt(np.power(sobel_x,2)+np.power(sobel_y,2))\n",
    "    # 4) Scale to 8-bit (0 - 255) and convert to type = np.uint8\n",
    "    scaled_sobel = np.uint8(255*abs_sobelxy/np.max(abs_sobelxy))\n",
    "    # 5) Create a binary mask where mag thresholds are met\n",
    "    mask = (scaled_sobel >= thresh_min) & (scaled_sobel <= thresh_max)\n",
    "    sxbinary = np.zeros_like(scaled_sobel)\n",
    "    sxbinary[mask]=1\n",
    "    # 6) Return this mask as your binary_output image\n",
    "    \n",
    "    return sxbinary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to calculate the direction of the gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dir_threshold(img, sobel_kernel, thresh):\n",
    "    thresh_min = thresh[0]\n",
    "    thresh_max = thresh[1]\n",
    "    # Apply the following steps to img\n",
    "    # 1) Convert to grayscale\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
    "    # 2) Take the gradient in x and y separately\n",
    "    sobel_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0,ksize=sobel_kernel)\n",
    "    sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1,ksize=sobel_kernel)\n",
    "    # 3) Take the absolute value of the x and y gradients\n",
    "    abs_sobel_x = np.absolute(sobel_x)\n",
    "    abs_sobel_y = np.absolute(sobel_y)\n",
    "    # 4) Use np.arctan2(abs_sobely, abs_sobelx) to calculate the direction of the gradient \n",
    "    dirn_gradient = np.arctan2(abs_sobel_y, abs_sobel_x)\n",
    "    # 5) Create a binary mask where direction thresholds are met\n",
    "    mask = (dirn_gradient >= thresh_min) & (dirn_gradient <= thresh_max)\n",
    "    # 6) Return this mask as your binary_output image\n",
    "    sxbinary = np.zeros_like(dirn_gradient)\n",
    "    sxbinary[mask]=1\n",
    "    return sxbinary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Sobel thresholds.\n",
    "**We shall first run the thresholds on one test_image and when we fine tune the thresholds**\n",
    "**we shall then check the thresholds on all test images**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Absolute sobel threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "998419ed27f34bb49f21b4c58fd1f6a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=20, description='thresh_min', max=255), IntSlider(value=200, description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n"
     ]
    }
   ],
   "source": [
    "from ipywidgets import interact, interactive, fixed\n",
    "def sobel_update(thresh_min=20, thresh_max=200):\n",
    "    test_image = cv2.imread(\"output_images/test_images/test5.jpg_Undistorted.jpg\")\n",
    "    dst = cal_undistort(test_image,mtx,dist)\n",
    "    output_img = abs_sobel_thresh(dst, 'x', thresh_min, thresh_max)\n",
    "    # Visualize sobel absolute threshold\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "    f.subplots_adjust(hspace = .2, wspace=.05)\n",
    "    ax1.imshow(cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB))\n",
    "    ax1.set_title('Unwarped Image', fontsize=30)\n",
    "    ax2.imshow(output_img, cmap='gray')\n",
    "    ax2.set_title('Sobel Absolute', fontsize=30)\n",
    "\n",
    "interact(sobel_update, \n",
    "         thresh_min=(0,255), \n",
    "         thresh_max=(0,255))\n",
    "\n",
    "print('...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Colorspaces thresholding\n",
    "[Colorspaces for lane detection](https://towardsdatascience.com/teaching-cars-to-see-advanced-lane-detection-using-computer-vision-87a01de0424f)\n",
    "***\n",
    "**Using information in the above link we shall attempt only the following thresholds**.\n",
    "**We shall first run the thresholds on one test_image and when we fine tune the thresholds**\n",
    "**we shall then check the thresholds on all test images**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R channel Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def R_threshold(image,thresh=(0, 255)):\n",
    "    R = image[:,:,0]\n",
    "    G = image[:,:,1]\n",
    "    B = image[:,:,2]\n",
    "    binary = np.zeros_like(R)\n",
    "    binary[(R > thresh[0]) & (R <= thresh[1])] = 1\n",
    "    return binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HLS S-channel Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def S_threshold(image,thresh=(0, 255)):\n",
    "    hls = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "    H = hls[:,:,0]\n",
    "    L = hls[:,:,1]\n",
    "    S = hls[:,:,2]\n",
    "    binary = np.zeros_like(H)\n",
    "    binary[(S > thresh[0]) & (S <= thresh[1])] = 1\n",
    "    return binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HLS L-channel Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_threshold(image,thresh=(0, 255)):\n",
    "    hls = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "    H = hls[:,:,0]\n",
    "    L = hls[:,:,1]\n",
    "    S = hls[:,:,2]\n",
    "    binary = np.zeros_like(H)\n",
    "    binary[(L > thresh[0]) & (L <= thresh[1])] = 1\n",
    "    return binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HSV V-channel Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def V_threshold(image,thresh=(0, 255)):\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    H = hsv[:,:,0]\n",
    "    S = hsv[:,:,1]\n",
    "    V = hsv[:,:,2]\n",
    "    binary = np.zeros_like(H)\n",
    "    binary[(V > thresh[0]) & (V <= thresh[1])] = 1\n",
    "    return binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LAB L-channel Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Lab_L_threshold(image,thresh=(0, 255)):\n",
    "    lab = cv2.cvtColor(image, cv2.COLOR_RGB2Lab)\n",
    "    L = lab[:,:,0]\n",
    "    A = lab[:,:,1]\n",
    "    B = lab[:,:,2]\n",
    "    binary = np.zeros_like(H)\n",
    "    binary[(L > thresh[0]) & (L <= thresh[1])] = 1\n",
    "    return binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LAB B-channel Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def B_threshold(image,thresh=(0, 255)):\n",
    "    lab = cv2.cvtColor(image, cv2.COLOR_RGB2Lab)\n",
    "    L = lab[:,:,0]\n",
    "    A = lab[:,:,1]\n",
    "    B = lab[:,:,2]\n",
    "    binary = np.zeros_like(H)\n",
    "    binary[(B > thresh[0]) & (B <= thresh[1])] = 1\n",
    "    return binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = cv2.imread(\"output_images/test_images/test5.jpg_Undistorted.jpg\")\n",
    "def color_update(min_thresh, max_thresh):\n",
    "    output_img_R = R_threshold(image,(min_thresh, max_thresh))\n",
    "    output_img_S = S_threshold(image,(min_thresh, max_thresh))\n",
    "    output_img_L = L_threshold(image,(min_thresh, max_thresh))\n",
    "    output_img_V = V_threshold(image,(min_thresh, max_thresh))\n",
    "    output_img_Lab_L = Lab_L_threshold(image,(min_thresh, max_thresh))\n",
    "    output_img_B = B_threshold(image,(min_thresh, max_thresh))    \n",
    "    \n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "    f.subplots_adjust(hspace = .2, wspace=.05)\n",
    "    \n",
    "    # Visualize R-channel threshold\n",
    "    ax1.imshow(cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB))\n",
    "    ax1.set_title('Undistorted Image', fontsize=30)\n",
    "    ax2.imshow(output_img_R, cmap='gray')\n",
    "    ax2.set_title('RGB R-Channel', fontsize=30)\n",
    "    \n",
    "    # Visualize S-channel threshold\n",
    "    ax1.imshow(cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB))\n",
    "    ax1.set_title('Undistorted Image', fontsize=30)\n",
    "    ax2.imshow(output_img_S, cmap='gray')\n",
    "    ax2.set_title('HLS S-Channel', fontsize=30)\n",
    "    \n",
    "    # Visualize L-channel threshold\n",
    "    ax1.imshow(cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB))\n",
    "    ax1.set_title('Undistorted Image', fontsize=30)\n",
    "    ax2.imshow(output_img_L, cmap='gray')\n",
    "    ax2.set_title('HLS L-Channel', fontsize=30)\n",
    "\n",
    "interact(update,\n",
    "         min_thresh=(0,255), \n",
    "         max_thresh=(0,255))\n",
    "\n",
    "print('...')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
